"""
Caelio Web API - REST API cho h·ªá th·ªëng ph√¢n lo·∫°i t√≠nh c√°ch ƒë·ªçc s√°ch
S·ª≠ d·ª•ng FastAPI
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
import pandas as pd
import os
from caelio_personality_system import CaelioPersonalitySystem
from caelio_book_matcher import CaelioBookMatcher

# Kh·ªüi t·∫°o FastAPI app
app = FastAPI(
    title="Caelio Personality API",
    description="API ph√¢n lo·∫°i t√≠nh c√°ch ƒë·ªçc s√°ch v√† g·ª£i √Ω s√°ch ph√π h·ª£p",
    version="1.0.0"
)

# CORS middleware ƒë·ªÉ frontend c√≥ th·ªÉ g·ªçi API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Trong production n√™n ch·ªâ ƒë·ªãnh c·ª• th·ªÉ domain
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Kh·ªüi t·∫°o h·ªá th·ªëng
personality_system = CaelioPersonalitySystem()
book_matcher = CaelioBookMatcher()

# === PYDANTIC MODELS ===

class PersonalityAnswers(BaseModel):
    """Model cho c√¢u tr·∫£ l·ªùi personality test - h√†nh tr√¨nh kh√°m ph√° (3 ho·∫∑c 8 c√¢u)"""
    Q1: str
    Q2: str
    Q3: str
    Q4: Optional[str] = None
    Q5: Optional[str] = None
    Q6: Optional[str] = None
    Q7: Optional[str] = None
    Q8: Optional[str] = None
    
    class Config:
        schema_extra = {
            "example_short": {
                "Q1": "A",
                "Q2": "C", 
                "Q3": "E"
            },
            "example_full": {
                "Q1": "A",
                "Q2": "C", 
                "Q3": "E",
                "Q4": "C",
                "Q5": "B",
                "Q6": "E",
                "Q7": "C",
                "Q8": "C"
            }
        }

class ProfessionalAnswers(BaseModel):
    """Model cho c√¢u tr·∫£ l·ªùi h√†nh tr√¨nh chuy√™n ng√†nh - 4 c√¢u h·ªèi"""
    Q1: str  # Lƒ©nh v·ª±c mu·ªën ƒë√†o s√¢u
    Q2: str  # M·ª•c ti√™u ƒë·ªçc  
    Q3: str  # Phong c√°ch h·ªçc
    Q4: str  # C√°ch tr√¨nh b√†y ∆∞a th√≠ch
    
    class Config:
        schema_extra = {
            "example": {
                "Q1": "A",  # Kinh t·∫ø - Qu·∫£n tr·ªã - T√†i ch√≠nh
                "Q2": "B",  # Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ th·ª±c t·∫ø
                "Q3": "B",  # T·ª± m√¨nh t√¨m li√™n k·∫øt (synthesizer potential)
                "Q4": "C"   # K·∫øt n·ªëi ƒëa ng√†nh (synthesizer)
            }
        }

class CombinedAnswers(BaseModel):
    """Model cho c√¢u tr·∫£ l·ªùi c·∫£ 2 h√†nh tr√¨nh"""
    discovery_answers: PersonalityAnswers
    professional_answers: ProfessionalAnswers

class PersonalityProfile(BaseModel):
    """Model cho k·∫øt qu·∫£ ph√¢n t√≠ch t√≠nh c√°ch"""
    primary_group: str
    secondary_group: Optional[str]
    primary_score: int
    secondary_score: int
    synthesizer_score: int
    is_synthesizer: bool
    profile_name: str
    english_name: str
    all_scores: Dict[str, int]
    is_multi_motivated: bool
    description: Dict[str, str]
    
class ProfessionalProfile(BaseModel):
    """Model cho k·∫øt qu·∫£ ph√¢n t√≠ch t√≠nh c√°ch chuy√™n ng√†nh"""
    # K·∫ø th·ª´a t·ª´ PersonalityProfile
    primary_group: str
    secondary_group: Optional[str]
    primary_score: int
    secondary_score: int
    synthesizer_score: int
    is_synthesizer: bool
    profile_name: str
    english_name: str
    all_scores: Dict[str, int]
    is_multi_motivated: bool
    description: Dict[str, str]
    
    # Th√¥ng tin chuy√™n ng√†nh
    field: str
    motivation: str
    learning_style: str
    presentation_preference: str
    professional_synthesizer_indicators: int

class BookRecommendation(BaseModel):
    """Model cho g·ª£i √Ω s√°ch"""
    product_id: Any
    title: str
    authors: Optional[str]
    category: str
    summary: Optional[str]
    personality_match_score: float
    cover_link: Optional[str]

class RecommendationResult(BaseModel):
    """Model cho k·∫øt qu·∫£ g·ª£i √Ω t·ªïng th·ªÉ"""
    profile: PersonalityProfile
    recommendations: List[BookRecommendation]
    total_matches: int
    match_distribution: Dict[str, int]

class QuestionData(BaseModel):
    """Model cho c√¢u h·ªèi"""
    question: str
    choices: Dict[str, Dict[str, Any]]  # S·ª≠ d·ª•ng Any thay v√¨ str ƒë·ªÉ h·ªó tr·ª£ c·∫£ bool v√† str

class BookDetail(BaseModel):
    """Model cho th√¥ng tin chi ti·∫øt s√°ch"""
    product_id: Any
    title: str
    authors: Optional[str]
    original_price: Optional[float]
    current_price: Optional[float]
    quantity: Optional[float]
    category: str
    n_review: Optional[int]
    avg_rating: Optional[float]
    pages: Optional[int]
    manufacturer: Optional[str]
    cover_link: Optional[str]
    summary: Optional[str]
    content: Optional[str]

class BookListItem(BaseModel):
    """Model cho item trong danh s√°ch s√°ch (kh√¥ng c√≥ content ƒë·∫ßy ƒë·ªß)"""
    product_id: Any
    title: str
    authors: Optional[str]
    original_price: Optional[float]
    current_price: Optional[float]
    category: str
    n_review: Optional[int]
    avg_rating: Optional[float]
    pages: Optional[int]
    manufacturer: Optional[str]
    cover_link: Optional[str]
    summary: Optional[str]

class BookListResponse(BaseModel):
    """Model cho response danh s√°ch s√°ch"""
    books: List[BookListItem]
    total: int
    page: int
    page_size: int
    total_pages: int
    has_next: bool
    has_prev: bool

# === HELPER FUNCTIONS ===

def safe_string_value(value, default=''):
    """Safely convert value to string, handling NaN"""
    if pd.isna(value):
        return default
    return str(value) if value is not None else default

def create_book_recommendation(book) -> BookRecommendation:
    """Create BookRecommendation object with safe string handling"""
    return BookRecommendation(
        product_id=safe_string_value(book.get('product_id', '')),
        title=safe_string_value(book.get('title', '')),
        authors=safe_string_value(book.get('authors', '')),
        category=safe_string_value(book.get('category', '')),
        summary=safe_string_value(book.get('summary', '')),
        personality_match_score=float(book.get('personality_match_score', 0.0)),
        cover_link=safe_string_value(book.get('cover_link', ''))
    )

def get_field_description(field: str) -> str:
    """L·∫•y m√¥ t·∫£ chi ti·∫øt v·ªÅ lƒ©nh v·ª±c chuy√™n ng√†nh"""
    descriptions = {
        'business': 'Kinh t·∫ø - Qu·∫£n tr·ªã - T√†i ch√≠nh: Lƒ©nh v·ª±c kinh doanh, qu·∫£n l√Ω v√† t√†i ch√≠nh',
        'humanities': 'X√£ h·ªôi - Nh√¢n vƒÉn: Khoa h·ªçc x√£ h·ªôi, vƒÉn h·ªçc, l·ªãch s·ª≠, tri·∫øt h·ªçc',
        'science': 'Khoa h·ªçc t·ª± nhi√™n: To√°n, l√Ω, h√≥a, sinh, ƒë·ªãa l√Ω',
        'technology': 'C√¥ng ngh·ªá - K·ªπ thu·∫≠t: IT, k·ªπ thu·∫≠t, c√¥ng ngh·ªá th√¥ng tin',
        'medical': 'Y - D∆∞·ª£c h·ªçc: Y khoa, d∆∞·ª£c ph·∫©m, s·ª©c kh·ªèe',
        'education': 'S∆∞ ph·∫°m - Gi√°o d·ª•c: Gi·∫£ng d·∫°y, ƒë√†o t·∫°o, ph√°t tri·ªÉn con ng∆∞·ªùi',
        'arts': 'Ngh·ªá thu·∫≠t - Thi·∫øt k·∫ø - Ki·∫øn tr√∫c: S√°ng t·∫°o, thi·∫øt k·∫ø, ngh·ªá thu·∫≠t',
        'agriculture': 'N√¥ng - L√¢m - Ng∆∞ nghi·ªáp: N√¥ng nghi·ªáp, l√¢m nghi·ªáp, th·ªßy s·∫£n'
    }
    return descriptions.get(field, 'Lƒ©nh v·ª±c kh√¥ng x√°c ƒë·ªãnh')

def get_learning_recommendations(motivation: str, style: str, presentation: str) -> Dict[str, str]:
    """L·∫•y g·ª£i √Ω h·ªçc t·∫≠p d·ª±a tr√™n motivation, style v√† presentation"""
    recommendations = {
        'motivation_advice': {
            'foundational': 'N√™n ƒë·ªçc s√°ch c√≥ h·ªá th·ªëng, t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao, c√≥ c·∫•u tr√∫c r√µ r√†ng',
            'practical': '∆Øu ti√™n s√°ch h∆∞·ªõng d·∫´n th·ª±c h√†nh, case study, c·∫©m nang ·ª©ng d·ª•ng',
            'exploratory': 'Th√≠ch h·ª£p v·ªõi s√°ch ph·∫£n bi·ªán, g√≥c nh√¨n ƒë·ªïi m·ªõi, t∆∞ duy ƒë·ªôt ph√°'
        },
        'style_advice': {
            'structured': 'Ph√π h·ª£p v·ªõi gi√°o tr√¨nh, s√°ch c√≥ l·ªô tr√¨nh h·ªçc t·∫≠p t·ª´ng b∆∞·ªõc',
            'integrative': 'N√™n ƒë·ªçc s√°ch li√™n ng√†nh, t·ªïng h·ª£p, c√≥ t√≠nh k·∫øt n·ªëi cao'
        },
        'presentation_advice': {
            'analytical': '∆Øa th√≠ch s√°ch chuy√™n s√¢u, c√≥ tr√≠ch d·∫´n, nghi√™n c·ª©u khoa h·ªçc',
            'narrative': 'Th√≠ch s√°ch k·ªÉ chuy·ªán, v√≠ d·ª• th·ª±c t·∫ø, d·ªÖ hi·ªÉu',
            'integrative': 'Ph√π h·ª£p v·ªõi s√°ch ƒëa ng√†nh, t∆∞ duy h·ªá th·ªëng'
        }
    }
    
    return {
        'motivation_tip': recommendations['motivation_advice'].get(motivation, ''),
        'style_tip': recommendations['style_advice'].get(style, ''),
        'presentation_tip': recommendations['presentation_advice'].get(presentation, '')
    }

def get_professional_book_suggestions(field: str, motivation: str, style: str, presentation: str) -> List[str]:
    """L·∫•y g·ª£i √Ω s√°ch d·ª±a tr√™n th√¥ng tin chuy√™n ng√†nh"""
    suggestions = []
    
    # G·ª£i √Ω d·ª±a tr√™n field
    field_books = {
        'business': ['S√°ch kinh t·∫ø', 'S√°ch qu·∫£n tr·ªã', 'S√°ch t√†i ch√≠nh', 'Case study kinh doanh'],
        'humanities': ['S√°ch vƒÉn h·ªçc', 'S√°ch l·ªãch s·ª≠', 'S√°ch tri·∫øt h·ªçc', 'S√°ch x√£ h·ªôi h·ªçc'],
        'science': ['S√°ch khoa h·ªçc ph·ªï th√¥ng', 'Gi√°o tr√¨nh khoa h·ªçc', 'Nghi√™n c·ª©u khoa h·ªçc'],
        'technology': ['S√°ch c√¥ng ngh·ªá', 'S√°ch l·∫≠p tr√¨nh', 'S√°ch k·ªπ thu·∫≠t', 'T√†i li·ªáu IT'],
        'medical': ['S√°ch y khoa', 'S√°ch d∆∞·ª£c', 'S√°ch s·ª©c kh·ªèe', 'Nghi√™n c·ª©u y h·ªçc'],
        'education': ['S√°ch gi√°o d·ª•c', 'S√°ch s∆∞ ph·∫°m', 'Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y'],
        'arts': ['S√°ch ngh·ªá thu·∫≠t', 'S√°ch thi·∫øt k·∫ø', 'S√°ch ki·∫øn tr√∫c', 'L√Ω thuy·∫øt ngh·ªá thu·∫≠t'],
        'agriculture': ['S√°ch n√¥ng nghi·ªáp', 'S√°ch l√¢m nghi·ªáp', 'S√°ch th·ªßy s·∫£n']
    }
    
    suggestions.extend(field_books.get(field, ['S√°ch chuy√™n ng√†nh']))
    
    # G·ª£i √Ω d·ª±a tr√™n motivation
    if motivation == 'foundational':
        suggestions.extend(['S√°ch gi√°o tr√¨nh', 'S√°ch c∆° b·∫£n'])
    elif motivation == 'practical':
        suggestions.extend(['S√°ch th·ª±c h√†nh', 'C·∫©m nang ·ª©ng d·ª•ng'])
    elif motivation == 'exploratory':
        suggestions.extend(['S√°ch ƒë·ªïi m·ªõi', 'S√°ch ph·∫£n bi·ªán'])
    
    return list(set(suggestions))  # Lo·∫°i b·ªè duplicate

def map_professional_to_personality_group(field: str, motivation: str, style: str, presentation: str) -> str:
    """Map t·ª´ professional answers sang personality group ph√π h·ª£p"""
    # Logic mapping d·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm c·ªßa t·ª´ng group
    
    # Business th∆∞·ªùng l√† Chinh ph·ª•c ho·∫∑c Ki·∫øn t·∫°o
    if field == 'business':
        if motivation == 'exploratory':
            return 'Chinh ph·ª•c'  # Kh√°m ph√° c∆° h·ªôi, th√°ch th·ª©c
        else:
            return 'Ki·∫øn t·∫°o'    # X√¢y d·ª±ng, ph√°t tri·ªÉn
    
    # Technology/Science th∆∞·ªùng l√† Tri th·ª©c ho·∫∑c Ki·∫øn t·∫°o
    elif field in ['technology', 'science']:
        if motivation == 'foundational':
            return 'Tri th·ª©c'    # T√¨m hi·ªÉu b·∫£n ch·∫•t
        else:
            return 'Ki·∫øn t·∫°o'    # ·ª®ng d·ª•ng th·ª±c t·∫ø
    
    # Humanities th∆∞·ªùng l√† K·∫øt n·ªëi ho·∫∑c Tri th·ª©c
    elif field == 'humanities':
        if style == 'integrative':
            return 'K·∫øt n·ªëi'     # Li√™n k·∫øt con ng∆∞·ªùi, x√£ h·ªôi
        else:
            return 'Tri th·ª©c'    # T√¨m hi·ªÉu s√¢u s·∫Øc
    
    # Arts th∆∞·ªùng l√† T·ª± do ho·∫∑c K·∫øt n·ªëi
    elif field == 'arts':
        if presentation == 'narrative':
            return 'K·∫øt n·ªëi'     # K·ªÉ chuy·ªán, c·∫£m x√∫c
        else:
            return 'T·ª± do'       # S√°ng t·∫°o, th·ªÉ hi·ªán c√° t√≠nh
    
    # Education th∆∞·ªùng l√† K·∫øt n·ªëi
    elif field == 'education':
        return 'K·∫øt n·ªëi'         # Gi√°o d·ª•c l√† k·∫øt n·ªëi con ng∆∞·ªùi
    
    # Medical th∆∞·ªùng l√† K·∫øt n·ªëi ho·∫∑c Tri th·ª©c
    elif field == 'medical':
        if motivation == 'practical':
            return 'K·∫øt n·ªëi'     # ChƒÉm s√≥c con ng∆∞·ªùi
        else:
            return 'Tri th·ª©c'    # Nghi√™n c·ª©u y h·ªçc
    
    # Agriculture th∆∞·ªùng l√† Ki·∫øn t·∫°o
    elif field == 'agriculture':
        return 'Ki·∫øn t·∫°o'        # X√¢y d·ª±ng, s·∫£n xu·∫•t
    
    # Default fallback
    return 'Tri th·ª©c'

def get_personality_keywords_for_matching(primary_group: str, is_synthesizer: bool) -> List[str]:
    """L·∫•y keywords ƒë·ªÉ match s√°ch theo personality group"""
    base_keywords = {
        'K·∫øt n·ªëi': [
            # T√¢m l√Ω - c·∫£m x√∫c
            't√¢m l√Ω', 'c·∫£m x√∫c', 't√¨nh y√™u', 'gia ƒë√¨nh', 'm·ªëi quan h·ªá', 'k·∫øt n·ªëi', 'giao ti·∫øp',
            'ƒë·ªìng c·∫£m', 'chia s·∫ª', 'y√™u th∆∞∆°ng', 'chƒÉm s√≥c', 'h·ªó tr·ª£', 'gi√∫p ƒë·ª°',
            # VƒÉn h·ªçc c·∫£m x√∫c
            'ti·ªÉu thuy·∫øt', 't·∫£n vƒÉn', 'h·ªìi k√Ω', 'nh·∫≠t k√Ω', 'th∆∞ t·ª´', 'truy·ªán ng·∫Øn',
            'vƒÉn h·ªçc', 't√¨nh c·∫£m', 'l√£ng m·∫°n', 'gia ƒë√¨nh', 'tu·ªïi th∆°', 'k·ª∑ ni·ªám',
            # Ph√°t tri·ªÉn b·∫£n th√¢n - m·ªëi quan h·ªá
            'ph√°t tri·ªÉn b·∫£n th√¢n', 'k·ªπ nƒÉng m·ªÅm', 'l√£nh ƒë·∫°o', 'teamwork', 'h·ª£p t√°c',
            'x√¢y d·ª±ng', 'nu√¥i d∆∞·ª°ng', 'gi√°o d·ª•c', 'con tr·∫ª', 'parenting'
        ],
        'T·ª± do': [
            # Du l·ªãch - kh√°m ph√°
            'du l·ªãch', 'kh√°m ph√°', 'phi√™u l∆∞u', 'x√™ d·ªãch', 'vƒÉn h√≥a', 'th·∫ø gi·ªõi',
            't·ª± do', 'ƒë·ªôc l·∫≠p', 'c√° nh√¢n', 'b·∫£n s·∫Øc', 'c√° t√≠nh', 'phong c√°ch',
            # Ngh·ªá thu·∫≠t - s√°ng t·∫°o  
            'ngh·ªá thu·∫≠t', 's√°ng t·∫°o', 'thi·∫øt k·∫ø', 'h·ªôi h·ªça', 'nhi·∫øp ·∫£nh', '√¢m nh·∫°c',
            'th·ªùi trang', 'l√†m ƒë·∫πp', 'phong c√°ch s·ªëng', 'lifestyle', 'trang tr√≠',
            # T∆∞ duy ƒë·ªôc l·∫≠p
            't∆∞ duy', 'suy nghƒ©', 'quan ƒëi·ªÉm', 'g√≥c nh√¨n', 'ph·∫£n bi·ªán', 'ƒë·ªôc ƒë√°o',
            'kh√°c bi·ªát', 'ƒë·ªïi m·ªõi', 's√°ng ki·∫øn', 'breakthrough', 'innovation'
        ],
        'Tri th·ª©c': [
            # Khoa h·ªçc - nghi√™n c·ª©u
            'khoa h·ªçc', 'nghi√™n c·ª©u', 'l√Ω thuy·∫øt', 'ph∆∞∆°ng ph√°p', 'ph√¢n t√≠ch', 'logic',
            'to√°n h·ªçc', 'v·∫≠t l√Ω', 'h√≥a h·ªçc', 'sinh h·ªçc', 'ƒë·ªãa l√Ω', 'thi√™n vƒÉn',
            'c√¥ng ngh·ªá', 'k·ªπ thu·∫≠t', 'm√°y t√≠nh', 'l·∫≠p tr√¨nh', 'ai', 'robotics',
            # L·ªãch s·ª≠ - tri·∫øt h·ªçc
            'l·ªãch s·ª≠', 'tri·∫øt h·ªçc', 't√¥n gi√°o', 'vƒÉn minh', 'nh√¢n lo·∫°i', 'x√£ h·ªôi',
            'ch√≠nh tr·ªã', 'kinh t·∫ø h·ªçc', 't√¢m l√Ω h·ªçc', 'x√£ h·ªôi h·ªçc', 'nh√¢n h·ªçc',
            # H·ªçc thu·∫≠t
            'gi√°o tr√¨nh', 'h·ªçc thu·∫≠t', 'nghi√™n c·ª©u', 'lu·∫≠n vƒÉn', 'b√†i b√°o', 'chuy√™n ng√†nh',
            'ƒë·∫°i h·ªçc', 'cao h·ªçc', 'ti·∫øn sƒ©', 'gi√°o s∆∞', 'chuy√™n gia', 'expert'
        ],
        'Chinh ph·ª•c': [
            # Th√†nh c√¥ng - l√£nh ƒë·∫°o
            'th√†nh c√¥ng', 'chi·∫øn th·∫Øng', 'ƒë·∫°t ƒë∆∞·ª£c', 'm·ª•c ti√™u', 'k·∫øt qu·∫£', 'hi·ªáu qu·∫£',
            'l√£nh ƒë·∫°o', 'qu·∫£n l√Ω', 'ƒëi·ªÅu h√†nh', 'ch·ªâ ƒë·∫°o', 'd·∫´n d·∫Øt', 'leadership',
            'CEO', 'gi√°m ƒë·ªëc', 's·∫øp', 'qu·∫£n l√Ω', 'teamlead', 'manager',
            # Th√°ch th·ª©c - c·∫°nh tranh
            'th√°ch th·ª©c', 'c·∫°nh tranh', 'ƒë·ªëi ƒë·∫ßu', 'v∆∞·ª£t qua', 'chinh ph·ª•c', 'ƒë·ªôt ph√°',
            'chi·∫øn l∆∞·ª£c', 'tactic', 'k·∫ø ho·∫°ch', 'planning', 'strategy', 'execution',
            # Truy·ªÅn c·∫£m h·ª©ng
            'truy·ªÅn c·∫£m h·ª©ng', 'ƒë·ªông l·ª±c', 'motivation', 'inspiring', 'passionate',
            'quy·∫øt t√¢m', '√Ω ch√≠', 'b·ªÅn b·ªâ', 'ki√™n tr√¨', 'v∆∞·ª£t kh√≥', 'overcome'
        ],
        'Ki·∫øn t·∫°o': [
            # Kinh doanh - kh·ªüi nghi·ªáp
            'kinh doanh', 'kh·ªüi nghi·ªáp', 'startup', 'doanh nghi·ªáp', 'c√¥ng ty', 'business',
            'marketing', 'b√°n h√†ng', 'sales', 'customer', 'kh√°ch h√†ng', 'th·ªã tr∆∞·ªùng',
            'ƒë·∫ßu t∆∞', 't√†i ch√≠nh', 'ng√¢n h√†ng', 'ch·ª©ng kho√°n', 'real estate', 'b·∫•t ƒë·ªông s·∫£n',
            # K·ªπ nƒÉng th·ª±c t·∫ø
            'k·ªπ nƒÉng', 'th·ª±c h√†nh', '·ª©ng d·ª•ng', 'practical', 'hands-on', 'tutorial',
            'h∆∞·ªõng d·∫´n', 'c·∫©m nang', 'manual', 'guide', 'how-to', 'step-by-step',
            # X√¢y d·ª±ng - ph√°t tri·ªÉn
            'x√¢y d·ª±ng', 'ph√°t tri·ªÉn', 'tƒÉng tr∆∞·ªüng', 'growth', 'scale', 'expansion',
            'h·ªá th·ªëng', 'quy tr√¨nh', 'process', 'system', 'framework', 'methodology'
        ]
    }
    
    keywords = base_keywords.get(primary_group, [])
    
    # N·∫øu l√† synthesizer, th√™m keywords li√™n ng√†nh
    if is_synthesizer:
        synthesizer_keywords = [
            'li√™n ng√†nh', 'ƒëa ng√†nh', 't·ªïng h·ª£p', 'k·∫øt h·ª£p', 't√≠ch h·ª£p', 'interdisciplinary',
            'multidisciplinary', 'cross-functional', 'holistic', 'comprehensive',
            't∆∞ duy h·ªá th·ªëng', 'systems thinking', 'big picture', 'to√†n c·∫£nh',
            'li√™n k·∫øt', 'k·∫øt n·ªëi', 'integration', 'synthesis', 'convergence'
        ]
        keywords.extend(synthesizer_keywords)
    
    return keywords

def create_book_list_item(book_row) -> BookListItem:
    """Create BookListItem object with safe string handling (without content)"""
    return BookListItem(
        product_id=safe_string_value(book_row.get('product_id', '')),
        title=safe_string_value(book_row.get('title', '')),
        authors=safe_string_value(book_row.get('authors', '')),
        original_price=float(book_row.get('original_price', 0)) if pd.notna(book_row.get('original_price')) else None,
        current_price=float(book_row.get('current_price', 0)) if pd.notna(book_row.get('current_price')) else None,
        category=safe_string_value(book_row.get('category', '')),
        n_review=int(book_row.get('n_review', 0)) if pd.notna(book_row.get('n_review')) else None,
        avg_rating=float(book_row.get('avg_rating', 0)) if pd.notna(book_row.get('avg_rating')) else None,
        pages=int(book_row.get('pages', 0)) if pd.notna(book_row.get('pages')) else None,
        manufacturer=safe_string_value(book_row.get('manufacturer', '')),
        cover_link=safe_string_value(book_row.get('cover_link', '')),
        summary=safe_string_value(book_row.get('summary', ''))
    )

def create_book_detail(book_row) -> BookDetail:
    """Create BookDetail object with safe string handling (with full content)"""
    return BookDetail(
        product_id=safe_string_value(book_row.get('product_id', '')),
        title=safe_string_value(book_row.get('title', '')),
        authors=safe_string_value(book_row.get('authors', '')),
        original_price=float(book_row.get('original_price', 0)) if pd.notna(book_row.get('original_price')) else None,
        current_price=float(book_row.get('current_price', 0)) if pd.notna(book_row.get('current_price')) else None,
        quantity=float(book_row.get('quantity', 0)) if pd.notna(book_row.get('quantity')) else None,
        category=safe_string_value(book_row.get('category', '')),
        n_review=int(book_row.get('n_review', 0)) if pd.notna(book_row.get('n_review')) else None,
        avg_rating=float(book_row.get('avg_rating', 0)) if pd.notna(book_row.get('avg_rating')) else None,
        pages=int(book_row.get('pages', 0)) if pd.notna(book_row.get('pages')) else None,
        manufacturer=safe_string_value(book_row.get('manufacturer', '')),
        cover_link=safe_string_value(book_row.get('cover_link', '')),
        summary=safe_string_value(book_row.get('summary', '')),
        content=' '.join(safe_string_value(book_row.get('content', '')).split()[:100])
    )

def load_book_database():
    """Load book database with fallback options"""
    book_file = 'dataset/books_full_data.csv'
    if not os.path.exists(book_file):
        fallback_files = [
            'books_full_data.csv',
            '../dataset/books_full_data.csv',
            'v2/labeled_books_v2.csv'
        ]
        
        for file_path in fallback_files:
            if os.path.exists(file_path):
                book_file = file_path
                break
        
        if not os.path.exists(book_file):
            raise HTTPException(status_code=404, detail="Book database not found")
    
    return pd.read_csv(book_file)


def ensure_complete_discovery_answers(answers: Dict[str, str]) -> Dict[str, str]:
    """Ensure answers dict contains Q1..Q8 by filling missing with a safe default (first available choice).

    This prevents the recommender from receiving an incomplete answers set when only Q1-Q3 are provided.
    """
    complete = answers.copy()
    for q in [f'Q{i}' for i in range(1, 9)]:
        if q not in complete or complete[q] is None:
            # pick the first available choice key for that question
            try:
                choices = personality_system.discovery_questions[q]['choices']
                if isinstance(choices, dict) and len(choices) > 0:
                    first_choice = next(iter(choices.keys()))
                    complete[q] = first_choice
                else:
                    complete[q] = 'A'
            except Exception:
                complete[q] = 'A'
    return complete

def get_personality_description(primary_group: str, is_synthesizer: bool) -> Dict[str, str]:
    """L·∫•y m√¥ t·∫£ chi ti·∫øt v·ªÅ nh√≥m t√≠nh c√°ch"""
    descriptions = {
        'K·∫øt n·ªëi': {
            'title': 'ü§ù The Connectors - Ng∆∞·ªùi K·∫øt n·ªëi',
            'description': 'B·∫°n ƒë·ªçc s√°ch ƒë·ªÉ t√¨m ki·∫øm s·ª± h√≤a h·ª£p, t√¨nh y√™u v√† c·∫£m gi√°c thu·ªôc v·ªÅ. B·∫°n th√≠ch nh·ªØng c√¢u chuy·ªán ch·∫°m ƒë·∫øn tr√°i tim, gi√∫p b·∫°n hi·ªÉu v√† ƒë·ªìng c·∫£m v·ªõi ng∆∞·ªùi kh√°c.',
            'books': 'T√¢m l√Ω t√¨nh c·∫£m, ch·ªØa l√†nh, t·∫£n vƒÉn, ti·ªÉu thuy·∫øt gia ƒë√¨nh',
            'traits': 'ƒê·ªìng c·∫£m cao, th√≠ch k·∫øt n·ªëi, ∆∞a c√¢u chuy·ªán c·∫£m ƒë·ªông'
        },
        'T·ª± do': {
            'title': 'üïäÔ∏è The Individuals - Ng∆∞·ªùi T·ª± do', 
            'description': 'B·∫°n t√¨m ki·∫øm t·ª± do, th·ªÉ hi·ªán b·∫£n s·∫Øc c√° nh√¢n v√† ph√° v·ª° khu√¥n m·∫´u. ƒê·ªçc s√°ch l√† c√°ch b·∫°n kh√°m ph√° th·∫ø gi·ªõi v√† ƒë·ªãnh h√¨nh c√° t√≠nh ri√™ng.',
            'books': 'Du k√Ω, ngh·ªá thu·∫≠t s·ªëng, ti·ªÉu thuy·∫øt s√°ng t·∫°o, s√°ch ph·∫£n t∆∞ x√£ h·ªôi',
            'traits': 'ƒê·ªôc l·∫≠p, s√°ng t·∫°o, th√≠ch kh√°m ph√° b·∫£n th√¢n'
        },
        'Tri th·ª©c': {
            'title': 'üß† The Thinkers - Ng∆∞·ªùi T∆∞ duy',
            'description': 'B·∫°n t√¨m ki·∫øm tri th·ª©c, s·ª± th·∫≠t v√† l√Ω gi·∫£i th·∫ø gi·ªõi. M·ªói cu·ªën s√°ch l√† m·ªôt c√¢u h·ªèi c·∫ßn ƒë∆∞·ª£c tr·∫£ l·ªùi, m·ªôt b√≠ ·∫©n c·∫ßn ƒë∆∞·ª£c kh√°m ph√°.',
            'books': 'Khoa h·ªçc ph·ªï th√¥ng, tri·∫øt h·ªçc, l·ªãch s·ª≠, s√°ch ph√¢n t√≠ch chuy√™n s√¢u',
            'traits': 'Hi·∫øu h·ªçc, logic, th√≠ch ph√¢n t√≠ch v√† t√¨m hi·ªÉu'
        },
        'Chinh ph·ª•c': {
            'title': 'üèÜ The Achievers - Ng∆∞·ªùi Chinh ph·ª•c',
            'description': 'B·∫°n mu·ªën v∆∞·ª£t qua th·ª≠ th√°ch, t·∫°o ra th√†nh t·ª±u v√† bi·∫øn √Ω t∆∞·ªüng th√†nh hi·ªán th·ª±c. S√°ch l√† c√¥ng c·ª• gi√∫p b·∫°n ƒë·∫°t ƒë∆∞·ª£c m·ª•c ti√™u.',
            'books': 'S√°ch truy·ªÅn c·∫£m h·ª©ng, l√£nh ƒë·∫°o, chi·∫øn l∆∞·ª£c, h·ªìi k√Ω th√†nh c√¥ng',
            'traits': 'Quy·∫øt ƒëo√°n, h∆∞·ªõng m·ª•c ti√™u, th√≠ch th√°ch th·ª©c'
        },
        'Ki·∫øn t·∫°o': {
            'title': 'üèóÔ∏è The Builders - Ng∆∞·ªùi X√¢y d·ª±ng',
            'description': 'B·∫°n mu·ªën x√¢y d·ª±ng n·ªÅn t·∫£ng v·ªØng ch·∫Øc, ph√°t tri·ªÉn k·ªπ nƒÉng th·ª±c t·∫ø. B·∫°n th√≠ch nh·ªØng cu·ªën s√°ch c√≥ t√≠nh ·ª©ng d·ª•ng cao.',
            'books': 'S√°ch k·ªπ nƒÉng, t√†i ch√≠nh, marketing, kh·ªüi nghi·ªáp, s√°ch h∆∞·ªõng nghi·ªáp',
            'traits': 'Th·ª±c t·∫ø, c√≥ h·ªá th·ªëng, th√≠ch x√¢y d·ª±ng v√† ph√°t tri·ªÉn'
        }
    }
    
    desc = descriptions[primary_group].copy()
    
    if is_synthesizer:
        desc['synthesizer_note'] = (
            "üîó ƒê·∫∑c ƒëi·ªÉm Synthesizer: B·∫°n c√≥ kh·∫£ nƒÉng t∆∞ duy t·ªïng h·ª£p cao, "
            "th√≠ch k·∫øt n·ªëi tri th·ª©c t·ª´ nhi·ªÅu lƒ©nh v·ª±c kh√°c nhau. Ph√π h·ª£p v·ªõi "
            "s√°ch c√≥ chi·ªÅu s√¢u v√† kh·∫£ nƒÉng li√™n k·∫øt ƒëa ng√†nh."
        )
    
    return desc

# === API ENDPOINTS ===

@app.get("/")
async def root():
    """Endpoint g·ªëc"""
    return {
        "message": "Caelio Personality API",
        "version": "1.0.0",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "message": "API is running"}

@app.get("/questions", response_model=Dict[str, QuestionData])
async def get_questions(question_type: str = "discovery"):
    """L·∫•y t·∫•t c·∫£ c√¢u h·ªèi cho personality test
    
    Args:
        question_type: 'discovery' cho h√†nh tr√¨nh kh√°m ph√°, 'professional' cho h√†nh tr√¨nh chuy√™n ng√†nh
    """
    if question_type == "discovery":
        source_questions = personality_system.discovery_questions
    elif question_type == "professional":
        source_questions = personality_system.professional_questions
    else:
        raise HTTPException(status_code=400, detail="question_type must be 'discovery' or 'professional'")
    
    questions = {}
    for q_id, question_data in source_questions.items():
        # Handle different choice formats between discovery and professional questions
        choices_formatted = {}
        for choice_id, choice_data in question_data['choices'].items():
            if question_type == "discovery":
                choices_formatted[choice_id] = {
                    'text': choice_data['text'],
                    'group': choice_data.get('group', ''),
                    'synthesizer': choice_data.get('synthesizer', False)
                }
            else:  # professional
                choices_formatted[choice_id] = {
                    'text': choice_data['text'],
                    'field': choice_data.get('field', ''),
                    'motivation': choice_data.get('motivation', ''),
                    'style': choice_data.get('style', ''),
                    'presentation': choice_data.get('presentation', ''),
                    'synthesizer_potential': choice_data.get('synthesizer_potential', False),
                    'synthesizer': choice_data.get('synthesizer', False)
                }
        
        questions[q_id] = QuestionData(
            question=question_data['question'],
            choices=choices_formatted
        )
    
    return questions

@app.get("/questions/{question_id}")
async def get_question(question_id: str, question_type: str = "discovery"):
    """L·∫•y c√¢u h·ªèi c·ª• th·ªÉ
    
    Args:
        question_id: ID c·ªßa c√¢u h·ªèi (Q1, Q2, ...)
        question_type: 'discovery' ho·∫∑c 'professional'
    """
    if question_type == "discovery":
        source_questions = personality_system.discovery_questions
    elif question_type == "professional":
        source_questions = personality_system.professional_questions
    else:
        raise HTTPException(status_code=400, detail="question_type must be 'discovery' or 'professional'")
    
    if question_id not in source_questions:
        raise HTTPException(status_code=404, detail="Question not found")
    
    question_data = source_questions[question_id]
    
    # Format choices based on question type
    choices_formatted = {}
    for choice_id, choice_data in question_data['choices'].items():
        if question_type == "discovery":
            choices_formatted[choice_id] = {
                'text': choice_data['text'],
                'group': choice_data.get('group', ''),
                'synthesizer': choice_data.get('synthesizer', False)
            }
        else:  # professional
            choices_formatted[choice_id] = {
                'text': choice_data['text'],
                'field': choice_data.get('field', ''),
                'motivation': choice_data.get('motivation', ''),
                'style': choice_data.get('style', ''),
                'presentation': choice_data.get('presentation', ''),
                'synthesizer_potential': choice_data.get('synthesizer_potential', False),
                'synthesizer': choice_data.get('synthesizer', False)
            }
    
    return QuestionData(
        question=question_data['question'],
        choices=choices_formatted
    )

@app.post("/analyze", response_model=PersonalityProfile)
async def analyze_personality(answers: PersonalityAnswers):
    """Ph√¢n t√≠ch t√≠nh c√°ch t·ª´ c√¢u tr·∫£ l·ªùi h√†nh tr√¨nh kh√°m ph√° (3 ho·∫∑c 8 c√¢u)"""
    try:
        # Chuy·ªÉn ƒë·ªïi sang format dictionary v√† lo·∫°i b·ªè None values
        answers_dict = {k: v for k, v in answers.dict().items() if v is not None}
        
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng c√¢u tr·∫£ l·ªùi (ph·∫£i l√† 3 ho·∫∑c 8)
        num_answers = len(answers_dict)
        if num_answers != 3 and num_answers != 8:
            raise HTTPException(status_code=400, detail="Must provide either 3 answers (Q1-Q3) or 8 answers (Q1-Q8)")
        
        # Validate answers
        for q_id, answer in answers_dict.items():
            if q_id not in personality_system.discovery_questions:
                raise HTTPException(status_code=400, detail=f"Invalid question ID: {q_id}")
            
            question_choices = personality_system.discovery_questions[q_id]['choices']
            if answer not in question_choices:
                raise HTTPException(status_code=400, detail=f"Invalid answer '{answer}' for question {q_id}")
        
        # Ph√¢n t√≠ch d·ª±a tr√™n s·ªë c√¢u tr·∫£ l·ªùi
        if num_answers == 3:
            # Ph√¢n t√≠ch s∆° b·ªô t·ª´ 3 c√¢u ƒë·∫ßu (WHY questions)
            profile = personality_system.calculate_partial_profile(answers_dict)
        else:
            # Ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß t·ª´ 8 c√¢u
            profile = personality_system.calculate_discovery_profile(answers_dict)
        
        # L·∫•y m√¥ t·∫£
        description = get_personality_description(profile['primary_group'], profile['is_synthesizer'])
        
        return PersonalityProfile(
            primary_group=profile['primary_group'],
            secondary_group=profile['secondary_group'],
            primary_score=profile['primary_score'],
            secondary_score=profile['secondary_score'],
            synthesizer_score=profile['synthesizer_score'],
            is_synthesizer=profile['is_synthesizer'],
            profile_name=profile['profile_name'],
            english_name=profile['english_name'],
            all_scores=profile['all_scores'],
            is_multi_motivated=profile['is_multi_motivated'],
            description=description
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error analyzing personality: {str(e)}")

@app.post("/analyze-professional", response_model=Dict[str, Any])
async def analyze_professional_personality(answers: ProfessionalAnswers):
    """Ph√¢n t√≠ch chuy√™n ng√†nh t·ª´ 4 c√¢u h·ªèi chuy√™n ng√†nh (Q1-Q4)"""
    try:
        # Chuy·ªÉn ƒë·ªïi sang format dictionary
        professional_dict = answers.dict()
        
        # Validate professional answers
        for q_id, answer in professional_dict.items():
            if q_id not in personality_system.professional_questions:
                raise HTTPException(status_code=400, detail=f"Invalid professional question ID: {q_id}")
            
            question_choices = personality_system.professional_questions[q_id]['choices']
            if answer not in question_choices:
                raise HTTPException(status_code=400, detail=f"Invalid answer '{answer}' for professional question {q_id}")
        
        # Ph√¢n t√≠ch th√¥ng tin chuy√™n ng√†nh
        field = personality_system.professional_questions['Q1']['choices'][professional_dict['Q1']]['field']
        motivation = personality_system.professional_questions['Q2']['choices'][professional_dict['Q2']]['motivation'] 
        style = personality_system.professional_questions['Q3']['choices'][professional_dict['Q3']]['style']
        presentation = personality_system.professional_questions['Q4']['choices'][professional_dict['Q4']]['presentation']
        
        # Ki·ªÉm tra Synthesizer ti·ªÅm nƒÉng trong chuy√™n ng√†nh
        synthesizer_indicators = 0
        if professional_dict['Q3'] == 'B':  # T·ª± m√¨nh t√¨m li√™n k·∫øt
            synthesizer_indicators += 1
        if professional_dict['Q4'] == 'C':  # K·∫øt n·ªëi ƒëa ng√†nh
            synthesizer_indicators += 1
        
        return {
            'field': field,
            'motivation': motivation,
            'learning_style': style,
            'presentation_preference': presentation,
            'professional_synthesizer_indicators': synthesizer_indicators,
            'is_professional_synthesizer': synthesizer_indicators >= 2,
            'field_description': get_field_description(field),
            'learning_recommendations': get_learning_recommendations(motivation, style, presentation)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error analyzing professional profile: {str(e)}")

@app.post("/recommend", response_model=RecommendationResult)
async def get_book_recommendations(answers: PersonalityAnswers, top_n: int = 20):
    """L·∫•y g·ª£i √Ω s√°ch d·ª±a tr√™n personality profile"""
    try:
        # Ph√¢n t√≠ch t√≠nh c√°ch
        answers_dict = answers.dict()
        profile = personality_system.calculate_discovery_profile(answers_dict)
        
        # Th√™m description
        description = get_personality_description(profile['primary_group'], profile['is_synthesizer'])
        
        # Load d·ªØ li·ªáu s√°ch
        book_df = load_book_database()
        
        # L·∫•y g·ª£i √Ω s√°ch v·ªõi improved matching (same as /discover)
        personality_keywords = get_personality_keywords_for_matching(profile['primary_group'], profile['is_synthesizer'])
        
        # Score v√† filter s√°ch
        scored_books = []
        for _, book in book_df.iterrows():
            cat = safe_string_value(book.get('category', '')).lower()
            title = safe_string_value(book.get('title', '')).lower() 
            summary = safe_string_value(book.get('summary', '')).lower()
            content = safe_string_value(book.get('content', '')).lower()
            
            # Calculate match score
            match_score = 0.0
            total_keywords = len(personality_keywords)
            
            for keyword in personality_keywords:
                keyword_score = 0
                if keyword in cat:
                    keyword_score += 3
                if keyword in title:
                    keyword_score += 2
                if keyword in summary:
                    keyword_score += 1
                if keyword in content:
                    keyword_score += 0.5
                
                if keyword_score > 0:
                    match_score += keyword_score / total_keywords
            
            # Sales and quality bonuses
            quantity = float(book.get('quantity', 0)) if pd.notna(book.get('quantity')) else 0
            sales_boost = min(quantity / 10000, 1.0) * 0.2
            
            avg_rating = float(book.get('avg_rating', 0)) if pd.notna(book.get('avg_rating')) else 0
            n_review = int(book.get('n_review', 0)) if pd.notna(book.get('n_review')) else 0
            
            rating_boost = (avg_rating / 5.0) * 0.1 if avg_rating > 0 else 0
            review_boost = min(n_review / 1000, 1.0) * 0.1 if n_review > 0 else 0
            
            final_score = match_score + sales_boost + rating_boost + review_boost
            
            if final_score > 0.05:
                scored_books.append((book, final_score))
        
        # Sort by score and sales
        scored_books.sort(key=lambda x: (x[1], float(x[0].get('quantity', 0)) if pd.notna(x[0].get('quantity')) else 0), reverse=True)
        
        # Create recommendations
        recommendations = []
        match_distribution = {}
        
        for book, score in scored_books[:top_n]:
            book_rec = create_book_recommendation(book)
            book_rec.personality_match_score = score
            recommendations.append(book_rec)
            
            category = safe_string_value(book.get('category', 'Unknown'))
            match_distribution[category] = match_distribution.get(category, 0) + 1
        
        # T·∫°o profile response
        profile_response = PersonalityProfile(
            primary_group=profile['primary_group'],
            secondary_group=profile['secondary_group'],
            primary_score=profile['primary_score'],
            secondary_score=profile['secondary_score'],
            synthesizer_score=profile['synthesizer_score'],
            is_synthesizer=profile['is_synthesizer'],
            profile_name=profile['profile_name'],
            english_name=profile['english_name'],
            all_scores=profile['all_scores'],
            is_multi_motivated=profile['is_multi_motivated'],
            description=description
        )
        
        return RecommendationResult(
            profile=profile_response,
            recommendations=recommendations,
            total_matches=len(scored_books),
            match_distribution=match_distribution
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting recommendations: {str(e)}")

@app.post("/recommend-professional", response_model=Dict[str, Any])
async def get_professional_book_recommendations(answers: ProfessionalAnswers, top_n: int = 20):
    """L·∫•y g·ª£i √Ω s√°ch d·ª±a tr√™n th√¥ng tin chuy√™n ng√†nh (4 c√¢u h·ªèi)"""
    try:
        # Ph√¢n t√≠ch th√¥ng tin chuy√™n ng√†nh
        professional_dict = answers.dict()
        
        # Validate professional answers
        for q_id, answer in professional_dict.items():
            if q_id not in personality_system.professional_questions:
                raise HTTPException(status_code=400, detail=f"Invalid professional question ID: {q_id}")
            
            question_choices = personality_system.professional_questions[q_id]['choices']
            if answer not in question_choices:
                raise HTTPException(status_code=400, detail=f"Invalid answer '{answer}' for professional question {q_id}")
        
        # Ph√¢n t√≠ch th√¥ng tin chuy√™n ng√†nh
        field = personality_system.professional_questions['Q1']['choices'][professional_dict['Q1']]['field']
        motivation = personality_system.professional_questions['Q2']['choices'][professional_dict['Q2']]['motivation'] 
        style = personality_system.professional_questions['Q3']['choices'][professional_dict['Q3']]['style']
        presentation = personality_system.professional_questions['Q4']['choices'][professional_dict['Q4']]['presentation']
        
        synthesizer_indicators = 0
        if professional_dict['Q3'] == 'B':
            synthesizer_indicators += 1
        if professional_dict['Q4'] == 'C':
            synthesizer_indicators += 1
        
        # G·ª£i √Ω s√°ch d·ª±a tr√™n field v√† motivation (ƒë∆°n gi·∫£n)
        book_recommendations = get_professional_book_suggestions(field, motivation, style, presentation)
        
        return {
            'professional_analysis': {
                'field': field,
                'motivation': motivation,
                'learning_style': style,
                'presentation_preference': presentation,
                'professional_synthesizer_indicators': synthesizer_indicators,
                'is_professional_synthesizer': synthesizer_indicators >= 2,
                'field_description': get_field_description(field),
                'learning_recommendations': get_learning_recommendations(motivation, style, presentation)
            },
            'book_suggestions': book_recommendations
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting professional recommendations: {str(e)}")

@app.post("/discover", response_model=RecommendationResult)
async def discover_and_recommend(answers: PersonalityAnswers, top_n: int = 20):
    """API t·ªïng h·ª£p: Ph√¢n t√≠ch t√≠nh c√°ch + G·ª£i √Ω s√°ch cho h√†nh tr√¨nh kh√°m ph√°"""
    try:
        # Chuy·ªÉn ƒë·ªïi sang format dictionary v√† lo·∫°i b·ªè None values
        answers_dict = {k: v for k, v in answers.dict().items() if v is not None}
        
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng c√¢u tr·∫£ l·ªùi (ph·∫£i l√† 3 ho·∫∑c 8)
        num_answers = len(answers_dict)
        if num_answers != 3 and num_answers != 8:
            raise HTTPException(status_code=400, detail="Must provide either 3 answers (Q1-Q3) or 8 answers (Q1-Q8)")
        
        # Validate answers
        for q_id, answer in answers_dict.items():
            if q_id not in personality_system.discovery_questions:
                raise HTTPException(status_code=400, detail=f"Invalid question ID: {q_id}")
            
            question_choices = personality_system.discovery_questions[q_id]['choices']
            if answer not in question_choices:
                raise HTTPException(status_code=400, detail=f"Invalid answer '{answer}' for question {q_id}")
        
        # Ph√¢n t√≠ch d·ª±a tr√™n s·ªë c√¢u tr·∫£ l·ªùi
        if num_answers == 3:
            # Ph√¢n t√≠ch s∆° b·ªô t·ª´ 3 c√¢u ƒë·∫ßu (WHY questions)
            profile = personality_system.calculate_partial_profile(answers_dict)
        else:
            # Ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß t·ª´ 8 c√¢u
            profile = personality_system.calculate_discovery_profile(answers_dict)
        
        # L·∫•y m√¥ t·∫£
        description = get_personality_description(profile['primary_group'], profile['is_synthesizer'])
        
        # Load d·ªØ li·ªáu s√°ch
        book_df = load_book_database()
        
        # L·∫•y g·ª£i √Ω s√°ch v·ªõi improved matching
        # Get keywords for personality matching
        personality_keywords = get_personality_keywords_for_matching(profile['primary_group'], profile['is_synthesizer'])
        
        # Score v√† filter s√°ch
        scored_books = []
        for _, book in book_df.iterrows():
            cat = safe_string_value(book.get('category', '')).lower()
            title = safe_string_value(book.get('title', '')).lower() 
            summary = safe_string_value(book.get('summary', '')).lower()
            content = safe_string_value(book.get('content', '')).lower()
            
            # Calculate match score based on keywords
            match_score = 0.0
            total_keywords = len(personality_keywords)
            
            for keyword in personality_keywords:
                keyword_score = 0
                if keyword in cat:
                    keyword_score += 3  # Category match is most important
                if keyword in title:
                    keyword_score += 2  # Title match is very important
                if keyword in summary:
                    keyword_score += 1  # Summary match is important
                if keyword in content:
                    keyword_score += 0.5  # Content match is less important
                
                if keyword_score > 0:
                    match_score += keyword_score / total_keywords
            
            # Bonus for sales volume (quantity)
            quantity = float(book.get('quantity', 0)) if pd.notna(book.get('quantity')) else 0
            sales_boost = min(quantity / 10000, 1.0) * 0.2  # Max 20% boost for high sales
            
            # Bonus for rating and reviews
            avg_rating = float(book.get('avg_rating', 0)) if pd.notna(book.get('avg_rating')) else 0
            n_review = int(book.get('n_review', 0)) if pd.notna(book.get('n_review')) else 0
            
            rating_boost = (avg_rating / 5.0) * 0.1 if avg_rating > 0 else 0  # Max 10% boost for high rating
            review_boost = min(n_review / 1000, 1.0) * 0.1 if n_review > 0 else 0  # Max 10% boost for many reviews
            
            final_score = match_score + sales_boost + rating_boost + review_boost
            
            if final_score > 0.05:  # Threshold for inclusion
                scored_books.append((book, final_score))
        
        # Sort by score (descending) and sales volume (descending)
        scored_books.sort(key=lambda x: (x[1], float(x[0].get('quantity', 0)) if pd.notna(x[0].get('quantity')) else 0), reverse=True)
        
        # Take top_n recommendations
        recommendations = []
        match_distribution = {}
        
        for book, score in scored_books[:top_n]:
            book_rec = create_book_recommendation(book)
            book_rec.personality_match_score = score
            recommendations.append(book_rec)
            
            # Track distribution
            category = safe_string_value(book.get('category', 'Unknown'))
            match_distribution[category] = match_distribution.get(category, 0) + 1
        
        # T·∫°o profile response
        profile_response = PersonalityProfile(
            primary_group=profile['primary_group'],
            secondary_group=profile['secondary_group'],
            primary_score=profile['primary_score'],
            secondary_score=profile['secondary_score'],
            synthesizer_score=profile['synthesizer_score'],
            is_synthesizer=profile['is_synthesizer'],
            profile_name=profile['profile_name'],
            english_name=profile['english_name'],
            all_scores=profile['all_scores'],
            is_multi_motivated=profile['is_multi_motivated'],
            description=description
        )
        
        return RecommendationResult(
            profile=profile_response,
            recommendations=recommendations,
            total_matches=len(scored_books),
            match_distribution=match_distribution
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error in discover and recommend: {str(e)}")

@app.post("/professional", response_model=RecommendationResult)
async def professional_and_recommend(answers: ProfessionalAnswers, top_n: int = 20):
    """API t·ªïng h·ª£p chuy√™n ng√†nh: Ph√¢n t√≠ch + G·ª£i √Ω s√°ch t·ª´ 4 c√¢u h·ªèi chuy√™n ng√†nh"""
    try:
        # Ph√¢n t√≠ch th√¥ng tin chuy√™n ng√†nh
        professional_dict = answers.dict()
        
        # Validate professional answers
        for q_id, answer in professional_dict.items():
            if q_id not in personality_system.professional_questions:
                raise HTTPException(status_code=400, detail=f"Invalid professional question ID: {q_id}")
            
            question_choices = personality_system.professional_questions[q_id]['choices']
            if answer not in question_choices:
                raise HTTPException(status_code=400, detail=f"Invalid answer '{answer}' for professional question {q_id}")
        
        # Ph√¢n t√≠ch th√¥ng tin chuy√™n ng√†nh
        field = personality_system.professional_questions['Q1']['choices'][professional_dict['Q1']]['field']
        motivation = personality_system.professional_questions['Q2']['choices'][professional_dict['Q2']]['motivation'] 
        style = personality_system.professional_questions['Q3']['choices'][professional_dict['Q3']]['style']
        presentation = personality_system.professional_questions['Q4']['choices'][professional_dict['Q4']]['presentation']
        
        # Ki·ªÉm tra Synthesizer ti·ªÅm nƒÉng
        synthesizer_indicators = 0
        if professional_dict['Q3'] == 'B':  # T·ª± m√¨nh t√¨m li√™n k·∫øt
            synthesizer_indicators += 1
        if professional_dict['Q4'] == 'C':  # K·∫øt n·ªëi ƒëa ng√†nh
            synthesizer_indicators += 1
        
        is_synthesizer = synthesizer_indicators >= 2
        
        # Map professional answers sang personality group h·ª£p l√Ω
        primary_group = map_professional_to_personality_group(field, motivation, style, presentation)
        
        # T·∫°o personality profile t·ª´ professional context
        profile = {
            'primary_group': primary_group,
            'secondary_group': None,
            'primary_score': 100,  # Professional context gives strong indication
            'secondary_score': 0,
            'synthesizer_score': synthesizer_indicators * 50,
            'is_synthesizer': is_synthesizer,
            'profile_name': f"{primary_group}{'‚ÄìSynthesizer' if is_synthesizer else ''}",
            'english_name': f"Professional {primary_group}{'‚ÄìSynthesizer' if is_synthesizer else ''}",
            'all_scores': {primary_group: 100, 'Synthesizer': synthesizer_indicators * 50},
            'is_multi_motivated': False
        }

        # Load book database
        book_df = load_book_database()

        # L·∫•y keywords cho matching d·ª±a tr√™n personality + field
        personality_keywords = get_personality_keywords_for_matching(primary_group, is_synthesizer)
        field_keywords = {
            'business': ['kinh doanh', 'marketing', 'b√°n h√†ng', 'qu·∫£n tr·ªã', 't√†i ch√≠nh', 'k·∫ø to√°n', 'ch·ª©ng kho√°n', 'ƒë·∫ßu t∆∞', 'kh·ªüi nghi·ªáp'],
            'humanities': ['vƒÉn h·ªçc', 'l·ªãch s·ª≠', 'tri·∫øt h·ªçc', 'x√£ h·ªôi', 'nh√¢n vƒÉn', 't√¥n gi√°o', 'vƒÉn h√≥a'],
            'science': ['khoa h·ªçc', 'to√°n h·ªçc', 'v·∫≠t l√Ω', 'h√≥a h·ªçc', 'sinh h·ªçc', 'ƒë·ªãa l√Ω', 'k·ªπ thu·∫≠t'],
            'technology': ['c√¥ng ngh·ªá', 'tin h·ªçc', 'l·∫≠p tr√¨nh', 'm√°y t√≠nh', 'internet', 'ai', 'robot'],
            'medical': ['y h·ªçc', 's·ª©c kh·ªèe', 'd∆∞·ª£c', 'y khoa', 'chƒÉm s√≥c', 'dinh d∆∞·ª°ng'],
            'education': ['gi√°o d·ª•c', 's∆∞ ph·∫°m', 'd·∫°y h·ªçc', 'ƒë√†o t·∫°o', 'tr·∫ª em'],
            'arts': ['ngh·ªá thu·∫≠t', 'h·ªôi h·ªça', 'thi·∫øt k·∫ø', 'ki·∫øn tr√∫c', '√¢m nh·∫°c', 'm√∫a', 'th·ªùi trang'],
            'agriculture': ['n√¥ng nghi·ªáp', 'l√¢m nghi·ªáp', 'th·ªßy s·∫£n', 'tr·ªìng tr·ªçt', 'chƒÉn nu√¥i']
        }
        
        # K·∫øt h·ª£p keywords t·ª´ personality v√† field
        all_keywords = personality_keywords + field_keywords.get(field, [])
        
        # Score v√† filter s√°ch
        scored_books = []
        for _, book in book_df.iterrows():
            cat = safe_string_value(book.get('category', '')).lower()
            title = safe_string_value(book.get('title', '')).lower() 
            summary = safe_string_value(book.get('summary', '')).lower()
            content = safe_string_value(book.get('content', '')).lower()
            
            # Calculate match score
            match_score = 0.0
            total_keywords = len(all_keywords)
            
            for keyword in all_keywords:
                keyword_score = 0
                if keyword in cat:
                    keyword_score += 3  # Category match is most important
                if keyword in title:
                    keyword_score += 2  # Title match is very important
                if keyword in summary:
                    keyword_score += 1  # Summary match is important
                if keyword in content:
                    keyword_score += 0.5  # Content match is less important
                
                if keyword_score > 0:
                    match_score += keyword_score / total_keywords
            
            # Bonus for sales volume (quantity)
            quantity = float(book.get('quantity', 0)) if pd.notna(book.get('quantity')) else 0
            sales_boost = min(quantity / 10000, 1.0) * 0.2  # Max 20% boost for high sales
            
            final_score = match_score + sales_boost
            
            if final_score > 0.05:  # Threshold for inclusion
                scored_books.append((book, final_score))
        
        # Sort by score (descending) and sales volume (descending)
        scored_books.sort(key=lambda x: (x[1], float(x[0].get('quantity', 0)) if pd.notna(x[0].get('quantity')) else 0), reverse=True)
        
        # Take top_n recommendations
        recommendations = []
        match_distribution = {}
        
        for book, score in scored_books[:top_n]:
            book_rec = create_book_recommendation(book)
            book_rec.personality_match_score = score
            recommendations.append(book_rec)
            
            # Track distribution
            category = safe_string_value(book.get('category', 'Unknown'))
            match_distribution[category] = match_distribution.get(category, 0) + 1

        # T·∫°o profile response
        description = get_personality_description(primary_group, is_synthesizer)
        profile_response = PersonalityProfile(
            primary_group=profile['primary_group'],
            secondary_group=profile['secondary_group'],
            primary_score=profile['primary_score'],
            secondary_score=profile['secondary_score'],
            synthesizer_score=profile['synthesizer_score'],
            is_synthesizer=profile['is_synthesizer'],
            profile_name=profile['profile_name'],
            english_name=profile['english_name'],
            all_scores=profile['all_scores'],
            is_multi_motivated=profile['is_multi_motivated'],
            description=description
        )

        return RecommendationResult(
            profile=profile_response,
            recommendations=recommendations,
            total_matches=len(scored_books),
            match_distribution=match_distribution
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error in professional and recommend: {str(e)}")

@app.get("/books", response_model=BookListResponse)
async def get_books(
    page: int = 1,
    page_size: int = 20,
    category: Optional[str] = None,
    author: Optional[str] = None,
    title: Optional[str] = None
):
    """L·∫•y danh s√°ch s√°ch v·ªõi ph√¢n trang v√† l·ªçc
    
    Args:
        page: S·ªë trang (b·∫Øt ƒë·∫ßu t·ª´ 1)
        page_size: S·ªë s√°ch m·ªói trang (t·ªëi ƒëa 100)
        category: L·ªçc theo category (t√¨m ki·∫øm t∆∞∆°ng ƒë·ªëi)
        author: L·ªçc theo t√°c gi·∫£ (t√¨m ki·∫øm t∆∞∆°ng ƒë·ªëi)
        title: L·ªçc theo ti√™u ƒë·ªÅ (t√¨m ki·∫øm t∆∞∆°ng ƒë·ªëi)
    """
    try:
        # Validate parameters
        if page < 1:
            raise HTTPException(status_code=400, detail="Page must be >= 1")
        if page_size < 1 or page_size > 100:
            raise HTTPException(status_code=400, detail="Page size must be between 1 and 100")
        
        # Load book database
        book_df = load_book_database()
        
        # Apply filters
        filtered_df = book_df.copy()
        
        if category:
            category_lower = category.lower()
            filtered_df = filtered_df[
                filtered_df['category'].str.lower().str.contains(category_lower, na=False, regex=False)
            ]
        
        if author:
            author_lower = author.lower()
            filtered_df = filtered_df[
                filtered_df['authors'].str.lower().str.contains(author_lower, na=False, regex=False)
            ]
        
        if title:
            title_lower = title.lower()
            filtered_df = filtered_df[
                filtered_df['title'].str.lower().str.contains(title_lower, na=False, regex=False)
            ]
        
        # Calculate pagination
        total = len(filtered_df)
        total_pages = (total + page_size - 1) // page_size  # Ceiling division
        
        # Get paginated results
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        paginated_df = filtered_df.iloc[start_idx:end_idx]
        
        # Convert to BookListItem objects
        books = []
        for _, book_row in paginated_df.iterrows():
            books.append(create_book_list_item(book_row))
        
        return BookListResponse(
            books=books,
            total=total,
            page=page,
            page_size=page_size,
            total_pages=total_pages,
            has_next=page < total_pages,
            has_prev=page > 1
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting books: {str(e)}")

@app.get("/books/{product_id}", response_model=BookDetail)
async def get_book_detail(product_id: str):
    """L·∫•y th√¥ng tin chi ti·∫øt c·ªßa m·ªôt cu·ªën s√°ch
    
    Args:
        product_id: ID s·∫£n ph·∫©m c·ªßa cu·ªën s√°ch
    """
    try:
        # Load book database
        book_df = load_book_database()
        
        # Find book by product_id
        # Convert product_id to string for comparison since it might be stored as different types
        book_matches = book_df[book_df['product_id'].astype(str) == str(product_id)]
        
        if len(book_matches) == 0:
            raise HTTPException(status_code=404, detail=f"Book with product_id '{product_id}' not found")
        
        # Get the first match (should be unique)
        book_row = book_matches.iloc[0]
        
        # Convert to BookDetail object
        return create_book_detail(book_row)
        
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting book detail: {str(e)}")

@app.get("/groups")
async def get_personality_groups():
    """L·∫•y danh s√°ch c√°c nh√≥m t√≠nh c√°ch"""
    return {
        "groups": personality_system.groups,
        "descriptions": {
            group: get_personality_description(group, False)
            for group in personality_system.groups.keys()
        }
    }

@app.get("/stats")
async def get_system_stats():
    """L·∫•y th·ªëng k√™ h·ªá th·ªëng"""
    try:
        # ƒê·∫øm s·ªë c√¢u h·ªèi
        num_discovery_questions = len(personality_system.discovery_questions)
        num_professional_questions = len(personality_system.professional_questions)
        
        # ƒê·∫øm s·ªë s√°ch (n·∫øu c√≥ database)
        num_books = 0
        try:
            book_df = pd.read_csv('dataset/books_full_data.csv')
            num_books = len(book_df)
        except:
            pass
        
        return {
            "discovery_questions": num_discovery_questions,
            "professional_questions": num_professional_questions,
            "total_questions": num_discovery_questions + num_professional_questions,
            "total_personality_groups": len(personality_system.groups),
            "total_books": num_books,
            "synthesizer_available": True,
            "journey_types": ["discovery", "professional"],
            "api_version": "1.0.0"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error getting stats: {str(e)}")

# === DEVELOPMENT ENDPOINTS ===

@app.post("/test/example")
async def test_example():
    """Test v·ªõi v√≠ d·ª• t·ª´ documentation"""
    example_answers = PersonalityAnswers(
        Q1="C", Q2="D", Q3="E", Q4="C", 
        Q5="B", Q6="E", Q7="C", Q8="C"
    )
    
    result = await analyze_personality(example_answers)
    return {
        "test_case": "Documentation example",
        "expected": "Thinker‚ÄìSynthesizer", 
        "actual": result.profile_name,
        "passed": "Tri th·ª©c" in result.profile_name and "Synthesizer" in result.profile_name,
        "profile": result
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)