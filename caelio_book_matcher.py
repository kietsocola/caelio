"""
T√≠ch h·ª£p h·ªá th·ªëng Caelio v·ªõi d·ªØ li·ªáu s√°ch
Mapping t·ª´ 5 nh√≥m t√≠nh c√°ch + Synthesizer sang categories s√°ch
"""

import pandas as pd
from caelio_personality_system import CaelioPersonalitySystem

class CaelioBookMatcher:
    def __init__(self):
        self.personality_system = CaelioPersonalitySystem()
        
        # Mapping t·ª´ nh√≥m t√≠nh c√°ch sang book categories
        self.personality_to_categories = {
            'K·∫øt n·ªëi': {
                'base': [
                    'S√°ch t∆∞ duy - K·ªπ nƒÉng s·ªëng',
                    'T√¢m l√Ω - Gi√°o d·ª•c gi·ªõi t√≠nh', 
                    'Gia ƒë√¨nh',
                    'Nu√¥i d·∫°y con',
                    'T√¨nh y√™u - H√¥n nh√¢n',
                    'X√£ h·ªôi',
                    'VƒÉn h√≥a - X√£ h·ªôi',
                    'T√¢m l√Ω h·ªçc',
                    'Giao ti·∫øp',
                    'Ti·ªÉu thuy·∫øt t√¨nh c·∫£m',
                    'Truy·ªán ng·∫Øn - T·∫£n vƒÉn'
                ],
                'synthesizer': [
                    'Tri·∫øt h·ªçc',
                    'T√¥n gi√°o',
                    'T√¢m l√Ω h·ªçc s√¢u',
                    'VƒÉn h·ªçc ph·∫£n t∆∞',
                    'Khoa h·ªçc x√£ h·ªôi'
                ]
            },
            
            'T·ª± do': {
                'base': [
                    'Du l·ªãch',
                    '·∫®m th·ª±c', 
                    'N·∫•u ƒÉn',
                    'S·ªü th√≠ch',
                    'Th·ªÉ thao - Gi·∫£i tr√≠',
                    'Nu√¥i tr·ªìng',
                    'L√†m v∆∞·ªùn',
                    'Thi·ªÅn',
                    'Yoga',
                    'Ngh·ªá thu·∫≠t s·ªëng',
                    'Phong c√°ch s·ªëng'
                ],
                'synthesizer': [
                    'Tri·∫øt h·ªçc v·ªÅ t·ª± do',
                    'Ngh·ªá thu·∫≠t',
                    'VƒÉn h·ªçc hi·ªán ƒë·∫°i',
                    'T∆∞ t∆∞·ªüng ƒë·ªôc l·∫≠p'
                ]
            },
            
            'Tri th·ª©c': {
                'base': [
                    'Khoa h·ªçc - K·ªπ thu·∫≠t',
                    'L·ªãch s·ª≠', 
                    'ƒê·ªãa l√Ω',
                    'Ch√≠nh tr·ªã - Ph√°p lu·∫≠t',
                    'S√°ch H·ªçc Ti·∫øng Anh',
                    'S√°ch gi√°o khoa',
                    'S√°ch chuy√™n ng√†nh',
                    'T·ª´ ƒëi·ªÉn',
                    'S√°ch tham kh·∫£o',
                    'Khoa h·ªçc ph·ªï th√¥ng'
                ],
                'synthesizer': [
                    'Tri·∫øt h·ªçc khoa h·ªçc',
                    'L·ªãch s·ª≠ t∆∞ t∆∞·ªüng',
                    'Khoa h·ªçc li√™n ng√†nh',
                    'T∆∞ duy h·ªá th·ªëng'
                ]
            },
            
            'Chinh ph·ª•c': {
                'base': [
                    'B√†i h·ªçc kinh doanh',
                    'S√°ch Marketing - B√°n h√†ng',
                    'S√°ch k·ªπ nƒÉng l√†m vi·ªác', 
                    'Qu·∫£n tr·ªã - L√£nh ƒë·∫°o',
                    'Kh·ªüi nghi·ªáp',
                    'T√†i ch√≠nh - K·∫ø to√°n',
                    'Ch·ª©ng kho√°n - ƒê·∫ßu t∆∞',
                    'B·∫•t ƒë·ªông s·∫£n',
                    'Th·ªÉ thao',
                    'B√≥ng ƒë√°',
                    'Truy·ªÅn c·∫£m h·ª©ng'
                ],
                'synthesizer': [
                    'Chi·∫øn l∆∞·ª£c c·∫•p cao',
                    'L√Ω thuy·∫øt qu·∫£n tr·ªã',
                    'Case study ph·ª©c t·∫°p',
                    'T∆∞ duy chi·∫øn l∆∞·ª£c'
                ]
            },
            
            'Ki·∫øn t·∫°o': {
                'base': [
                    'Ti·ªÉu Thuy·∫øt',
                    'Truy·ªán ng·∫Øn - T·∫£n vƒÉn - T·∫°p VƒÉn',
                    'Th∆° ca',
                    'T√°c ph·∫©m kinh ƒëi·ªÉn', 
                    'VƒÉn h·ªçc',
                    'Ngh·ªá thu·∫≠t',
                    'S√°ch ngh·ªá thu·∫≠t s·ªëng ƒë·∫πp',
                    '√Çm nh·∫°c',
                    'H·ªôi h·ªça',
                    'Nhi·∫øp ·∫£nh',
                    'Th·ªùi trang',
                    'L√†m ƒë·∫πp',
                    'Ki·∫øn tr√∫c',
                    'Thi·∫øt k·∫ø'
                ],
                'synthesizer': [
                    'Ngh·ªá thu·∫≠t ƒë∆∞∆°ng ƒë·∫°i',
                    'L√Ω thuy·∫øt s√°ng t·∫°o',
                    'VƒÉn h·ªçc hi·ªán ƒë·∫°i',
                    'Tri·∫øt h·ªçc ngh·ªá thu·∫≠t'
                ]
            }
        }
    
    def map_personality_to_books(self, profile, book_df):
        """
        L·ªçc s√°ch ph√π h·ª£p d·ª±a tr√™n personality profile v·ªõi fuzzy matching
        """
        primary_group = profile['primary_group']
        is_synthesizer = profile['is_synthesizer']
        
        # L·∫•y danh s√°ch categories ph√π h·ª£p
        if is_synthesizer:
            target_categories = (
                self.personality_to_categories[primary_group]['base'] +
                self.personality_to_categories[primary_group]['synthesizer']
            )
        else:
            target_categories = self.personality_to_categories[primary_group]['base']
        
        # S·ª≠ d·ª•ng fuzzy matching thay v√¨ exact match
        def matches_any_target(actual_category):
            if pd.isna(actual_category):
                return False
            actual_lower = str(actual_category).lower()
            for target in target_categories:
                target_lower = target.lower()
                # Exact match
                if actual_lower == target_lower:
                    return True
                # Substring match (c·∫£ 2 chi·ªÅu)
                if target_lower in actual_lower or actual_lower in target_lower:
                    return True
                # Keyword matching cho m·ªôt s·ªë cases ƒë·∫∑c bi·ªát
                if self._keyword_match(actual_lower, target_lower):
                    return True
            return False
        
        # L·ªçc s√°ch theo categories v·ªõi fuzzy matching
        matched_books = book_df[book_df['category'].apply(matches_any_target)].copy()
        
        # Th√™m matching score
        matched_books['personality_match_score'] = matched_books['category'].apply(
            lambda cat: self._calculate_match_score_fuzzy(cat, primary_group, is_synthesizer, target_categories)
        )
        
        # S·∫Øp x·∫øp theo ƒë·ªô ph√π h·ª£p
        matched_books = matched_books.sort_values('personality_match_score', ascending=False)
        
        return matched_books
    
    def _keyword_match(self, actual_lower, target_lower):
        """Ki·ªÉm tra keyword matching cho c√°c cases ƒë·∫∑c bi·ªát"""
        # Mapping keywords cho m·ªôt s·ªë categories ph·ªï bi·∫øn
        keyword_maps = {
            't√¢m l√Ω': ['psychology', 't√¢m l√≠', 't√¢m th·∫ßn', 'mental'],
            'kinh doanh': ['business', 'b√°n h√†ng', 'marketing', 'qu·∫£n tr·ªã', 'startup'],
            'khoa h·ªçc': ['science', 'k·ªπ thu·∫≠t', 'c√¥ng ngh·ªá', 'technology'],
            'vƒÉn h·ªçc': ['literature', 'ti·ªÉu thuy·∫øt', 'truy·ªán', 't√°c ph·∫©m'],
            'ngh·ªá thu·∫≠t': ['art', 'h·ªôi h·ªça', 'thi·∫øt k·∫ø', 'design'],
            'du l·ªãch': ['travel', 'du k√Ω', 'phi√™u l∆∞u'],
            's·ª©c kh·ªèe': ['health', 'y h·ªçc', 'medical', 'l√†m ƒë·∫πp'],
            't√†i ch√≠nh': ['finance', 'ti·ªÅn t·ªá', 'ƒë·∫ßu t∆∞', 'investment', 'ch·ª©ng kho√°n']
        }
        
        for key_target, related_words in keyword_maps.items():
            if key_target in target_lower:
                for word in related_words:
                    if word in actual_lower:
                        return True
        return False

    def _calculate_match_score_fuzzy(self, category, primary_group, is_synthesizer, target_categories):
        """T√≠nh ƒëi·ªÉm ph√π h·ª£p cho category v·ªõi fuzzy matching"""
        if pd.isna(category):
            return 0.1
            
        actual_lower = str(category).lower()
        base_categories = self.personality_to_categories[primary_group]['base']
        synth_categories = self.personality_to_categories[primary_group]['synthesizer']
        
        max_score = 0.1  # Default low score
        
        # Ki·ªÉm tra exact match tr∆∞·ªõc
        for target in target_categories:
            target_lower = target.lower()
            if actual_lower == target_lower:
                if target in synth_categories and is_synthesizer:
                    return 1.0  # Perfect match cho Synthesizer
                elif target in base_categories:
                    return 0.9  # Near perfect cho base exact match
                else:
                    max_score = max(max_score, 0.8)
        
        # Ki·ªÉm tra substring match
        for target in target_categories:
            target_lower = target.lower()
            if target_lower in actual_lower or actual_lower in target_lower:
                if target in synth_categories and is_synthesizer:
                    max_score = max(max_score, 0.8)  # Good match cho Synthesizer substring
                elif target in base_categories:
                    max_score = max(max_score, 0.7)  # Good match cho base substring
                else:
                    max_score = max(max_score, 0.6)
        
        # Ki·ªÉm tra keyword match
        for target in target_categories:
            target_lower = target.lower()
            if self._keyword_match(actual_lower, target_lower):
                if target in synth_categories and is_synthesizer:
                    max_score = max(max_score, 0.6)  # OK match cho Synthesizer keywords
                elif target in base_categories:
                    max_score = max(max_score, 0.5)  # OK match cho base keywords
                else:
                    max_score = max(max_score, 0.4)
        
        return max_score
    
    def get_personalized_recommendations(self, answers, book_df, top_n=20):
        """
        ƒê∆∞a ra g·ª£i √Ω s√°ch c√° nh√¢n h√≥a
        """
        # T√≠nh personality profile
        profile = self.personality_system.calculate_discovery_profile(answers)
        
        # L·ªçc s√°ch ph√π h·ª£p
        matched_books = self.map_personality_to_books(profile, book_df)
        
        # L·∫•y top N s√°ch
        top_recommendations = matched_books.head(top_n)
        
        return {
            'profile': profile,
            'recommendations': top_recommendations,
            'total_matches': len(matched_books),
            'match_distribution': matched_books.groupby('category').size().to_dict()
        }
    
    def analyze_book_compatibility(self, book_df):
        """
        Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng th√≠ch c·ªßa t·ª´ng s√°ch v·ªõi c√°c nh√≥m t√≠nh c√°ch
        """
        results = []
        
        for _, book in book_df.iterrows():
            book_analysis = {
                'product_id': book['product_id'],
                'title': book['title'],
                'category': book['category'],
                'compatibility': {}
            }
            
            # Ki·ªÉm tra ƒë·ªô t∆∞∆°ng th√≠ch v·ªõi t·ª´ng nh√≥m
            for group in self.personality_to_categories.keys():
                base_score = 0.8 if book['category'] in self.personality_to_categories[group]['base'] else 0
                synth_score = 1.0 if book['category'] in self.personality_to_categories[group]['synthesizer'] else 0
                
                book_analysis['compatibility'][group] = {
                    'base_match': base_score > 0,
                    'synthesizer_match': synth_score > 0,
                    'max_score': max(base_score, synth_score)
                }
            
            # T√¨m nh√≥m ph√π h·ª£p nh·∫•t
            best_group = max(
                book_analysis['compatibility'].items(), 
                key=lambda x: x[1]['max_score']
            )
            
            book_analysis['best_match_group'] = best_group[0]
            book_analysis['best_match_score'] = best_group[1]['max_score']
            
            results.append(book_analysis)
        
        return results

def demo_personality_matching():
    """Demo h·ªá th·ªëng matching"""
    # Kh·ªüi t·∫°o
    matcher = CaelioBookMatcher()
    
    # Load d·ªØ li·ªáu s√°ch (gi·∫£ s·ª≠ c√≥ file CSV)
    try:
        book_df = pd.read_csv('dataset/books_full_data.csv')
        print(f"üìö Loaded {len(book_df)} books")
    except:
        # T·∫°o d·ªØ li·ªáu m·∫´u n·∫øu kh√¥ng c√≥ file
        sample_books = [
            {'product_id': 1, 'title': 'C√¢y Cam Ng·ªçt C·ªßa T√¥i', 'category': 'Ti·ªÉu Thuy·∫øt'},
            {'product_id': 2, 'title': 'Thao T√∫ng T√¢m L√Ω', 'category': 'S√°ch t∆∞ duy - K·ªπ nƒÉng s·ªëng'},
            {'product_id': 3, 'title': 'Nh√† Gi·∫£ Kim', 'category': 'T√°c ph·∫©m kinh ƒëi·ªÉn'},
            {'product_id': 4, 'title': 'Marketing 4.0', 'category': 'S√°ch Marketing - B√°n h√†ng'},
            {'product_id': 5, 'title': 'L·ªãch S·ª≠ Th·∫ø Gi·ªõi', 'category': 'L·ªãch s·ª≠'},
        ]
        book_df = pd.DataFrame(sample_books)
        print(f"üìö Using {len(book_df)} sample books")
    
    # Test v·ªõi profile m·∫´u
    test_answers = {
        'Q1': 'A',  # K·∫øt n·ªëi
        'Q2': 'A',  # K·∫øt n·ªëi  
        'Q3': 'A',  # K·∫øt n·ªëi
        'Q4': 'A',  # Tri th·ª©c (ƒë·ªçc s√¢u)
        'Q5': 'A',  # K·∫øt n·ªëi
        'Q6': 'A',  # K·∫øt n·ªëi
        'Q7': 'A',  # K·∫øt n·ªëi
        'Q8': 'A'   # K·∫øt n·ªëi
    }
    
    # T√≠nh to√°n g·ª£i √Ω
    result = matcher.get_personalized_recommendations(test_answers, book_df)
    
    print(f"\n=== K·∫æT QU·∫¢ PH√ÇN T√çCH ===")
    print(f"Profile: {result['profile']['profile_name']}")
    print(f"T·ªïng s√°ch ph√π h·ª£p: {result['total_matches']}")
    print(f"\nTop recommendations:")
    
    if len(result['recommendations']) > 0:
        for _, book in result['recommendations'].head(5).iterrows():
            print(f"- {book['title']} ({book['category']}) - Score: {book['personality_match_score']:.2f}")
    else:
        print("Kh√¥ng c√≥ s√°ch ph√π h·ª£p trong dataset m·∫´u")
    
    return result

def create_personality_labeled_dataset():
    """
    T·∫°o dataset v·ªõi personality labels cho t·∫•t c·∫£ s√°ch
    """
    matcher = CaelioBookMatcher()
    
    try:
        # Load dataset
        book_df = pd.read_csv('dataset/books_full_data.csv')
        print(f"üìö Processing {len(book_df)} books...")
        
        # Ph√¢n t√≠ch compatibility
        compatibility_results = matcher.analyze_book_compatibility(book_df)
        
        # Chuy·ªÉn th√†nh DataFrame
        compatibility_df = pd.DataFrame([
            {
                'product_id': result['product_id'],
                'title': result['title'], 
                'category': result['category'],
                'best_personality_match': result['best_match_group'],
                'match_score': result['best_match_score'],
                'ket_noi_match': result['compatibility']['K·∫øt n·ªëi']['max_score'],
                'tu_do_match': result['compatibility']['T·ª± do']['max_score'],
                'tri_thuc_match': result['compatibility']['Tri th·ª©c']['max_score'],
                'chinh_phuc_match': result['compatibility']['Chinh ph·ª•c']['max_score'],
                'kien_tao_match': result['compatibility']['Ki·∫øn t·∫°o']['max_score']
            }
            for result in compatibility_results
        ])
        
        # Merge v·ªõi d·ªØ li·ªáu g·ªëc
        final_df = book_df.merge(compatibility_df, on='product_id', how='left')
        
        # L∆∞u file
        output_file = 'dataset/books_with_personality_labels.csv'
        final_df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"‚úÖ Saved to: {output_file}")
        
        # Th·ªëng k√™
        print(f"\nüìä Personality distribution:")
        print(compatibility_df['best_personality_match'].value_counts())
        
        return final_df
        
    except FileNotFoundError:
        print("‚ùå File dataset/books_full_data.csv not found")
        return None

if __name__ == "__main__":
    print("=== CAELIO BOOK MATCHING SYSTEM ===")
    
    # Demo
    demo_personality_matching()
    
    print("\n" + "="*50)
    
    # T·∫°o dataset v·ªõi personality labels
    create_personality_labeled_dataset()